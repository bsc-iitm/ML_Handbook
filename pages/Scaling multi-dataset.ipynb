{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Comprehensive Study on the Impact of Feature Scaling on Classification Models\"\n",
    "author: \"Sherry Thomas\"\n",
    "format:\n",
    "  html:\n",
    "    theme: theme.scss\n",
    "    toc: true\n",
    "    html-math-method: katex\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In the realm of machine learning, feature scaling is a crucial preprocessing step that can significantly influence the performance of classification models. It involves transforming the data to a common scale, ensuring that no single feature dominates the learning process due to its range of values. This notebook presents an exhaustive exploration of the impact of various feature scaling methods on classification models. We will focus on five commonly used techniques:\n",
    "\n",
    "1. Standard Scaler\n",
    "2. Min-max Scaler\n",
    "3. Maximum Absolute Scaler\n",
    "4. Robust Scaler\n",
    "5. Quantile Transformer\n",
    "\n",
    "We will use four different datasets provided by scikit-learn, which are frequently employed for classification tasks:\n",
    "\n",
    "1. Iris dataset\n",
    "2. Digits dataset\n",
    "3. Wine dataset\n",
    "4. Breast Cancer dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries\n",
    "\n",
    "Before we begin, we need to import the required libraries for data manipulation, visualization, and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris, load_digits, load_wine, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, QuantileTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Datasets\n",
    "\n",
    "We start by loading the four datasets and inspecting their structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the datasets\n",
    "iris = load_iris()\n",
    "digits = load_digits()\n",
    "wine = load_wine()\n",
    "breast_cancer = load_breast_cancer()\n",
    "\n",
    "# Create DataFrames for the datasets\n",
    "iris_df = pd.DataFrame(data=np.c_[iris['data'], iris['target']], columns=iris['feature_names'] + ['target'])\n",
    "digits_df = pd.DataFrame(data=np.c_[digits['data'], digits['target']], columns=digits['feature_names'] + ['target'])\n",
    "wine_df = pd.DataFrame(data=np.c_[wine['data'], wine['target']], columns=wine['feature_names'] + ['target'])\n",
    "breast_cancer_df = pd.DataFrame(data=np.c_[breast_cancer['data'], breast_cancer['target']], columns=list(breast_cancer['feature_names']) + ['target'])\n",
    "\n",
    "# Display the first few rows of iris dataset\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  target  \n",
       "0                          3.92   1065.0     0.0  \n",
       "1                          3.40   1050.0     0.0  \n",
       "2                          3.17   1185.0     0.0  \n",
       "3                          3.45   1480.0     0.0  \n",
       "4                          2.93    735.0     0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of wine dataset\n",
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890     0.0  \n",
       "1          0.2750                  0.08902     0.0  \n",
       "2          0.3613                  0.08758     0.0  \n",
       "3          0.6638                  0.17300     0.0  \n",
       "4          0.2364                  0.07678     0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of breast cancer dataset\n",
    "breast_cancer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets contain various features related to their respective domains, with a 'target' column indicating the class labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Before we proceed with feature scaling, we need to split the data for each dataset into training and testing sets. Additionally, to make our study more robust and thorough, we will create noisy versions of the datasets by adding random noise to the feature values. These noisy datasets will introduce variations that can better showcase the effects of different scaling methods on classification model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create noisy datasets\n",
    "def create_noisy_dataset(dataset, noise_std=0.2, test_size=0.2, random_state=42):\n",
    "    X = dataset.data\n",
    "    y = dataset.target\n",
    "\n",
    "    np.random.seed(random_state)\n",
    "    noise = np.random.normal(0, noise_std, size=X.shape)\n",
    "    X_noisy = X + noise\n",
    "\n",
    "    X_train_noisy, X_test_noisy, y_train, y_test = train_test_split(X_noisy, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    return X_train_noisy, X_test_noisy, y_train, y_test\n",
    "\n",
    "# Create noisy datasets for all four datasets\n",
    "X_train_iris_noisy, X_test_iris_noisy, y_train_iris, y_test_iris = create_noisy_dataset(iris)\n",
    "X_train_digits_noisy, X_test_digits_noisy, y_train_digits, y_test_digits = create_noisy_dataset(digits)\n",
    "X_train_wine_noisy, X_test_wine_noisy, y_train_wine, y_test_wine = create_noisy_dataset(wine)\n",
    "X_train_breast_cancer_noisy, X_test_breast_cancer_noisy, y_train_breast_cancer, y_test_breast_cancer = create_noisy_dataset(breast_cancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Standard Scaler\n",
    "\n",
    "The Standard Scaler ($SS$) transforms the data so that it has a mean ($\\mu$) of 0 and a standard deviation ($\\sigma$) of 1. This method assumes that the data is normally distributed. The transformation is given by:\n",
    "\n",
    "$$\n",
    "SS(x) = \\frac{x - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "where $x$ is the original feature vector, $\\mu$ is the mean of the feature vector, and $\\sigma$ is the standard deviation of the feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to apply Standard Scaler to a dataset\n",
    "def apply_standard_scaler(X_train, X_test):\n",
    "    standard_scaler = StandardScaler()\n",
    "    X_train_scaled = standard_scaler.fit_transform(X_train)\n",
    "    X_test_scaled = standard_scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "# Apply Standard Scaler to all four datasets\n",
    "X_train_iris_standard, X_test_iris_standard = apply_standard_scaler(X_train_iris_noisy, X_test_iris_noisy)\n",
    "X_train_digits_standard, X_test_digits_standard = apply_standard_scaler(X_train_digits_noisy, X_test_digits_noisy)\n",
    "X_train_wine_standard, X_test_wine_standard = apply_standard_scaler(X_train_wine_noisy, X_test_wine_noisy)\n",
    "X_train_breast_cancer_standard, X_test_breast_cancer_standard = apply_standard_scaler(X_train_breast_cancer_noisy, X_test_breast_cancer_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Min-max Scaler\n",
    "\n",
    "The Min-max Scaler ($MMS$) scales the data to a specific range, typically between 0 and 1. It is suitable for data that does not follow a normal distribution. The transformation is given by:\n",
    "\n",
    "$$\n",
    "MMS(x) = \\frac{x - x_{min}}{x_{max} - x_{min}}\n",
    "$$\n",
    "\n",
    "where $x$ is the original feature vector, $x_{min}$ is the smallest value in the feature vector, and $x_{max}$ is the largest value in the feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to apply Min-max Scaler to a dataset\n",
    "def apply_min_max_scaler(X_train, X_test):\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    X_train_scaled = min_max_scaler.fit_transform(X_train)\n",
    "    X_test_scaled = min_max_scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "# Apply Min-max Scaler to all four datasets\n",
    "X_train_iris_minmax, X_test_iris_minmax = apply_min_max_scaler(X_train_iris_noisy, X_test_iris_noisy)\n",
    "X_train_digits_minmax, X_test_digits_minmax = apply_min_max_scaler(X_train_digits_noisy, X_test_digits_noisy)\n",
    "X_train_wine_minmax, X_test_wine_minmax = apply_min_max_scaler(X_train_wine_noisy, X_test_wine_noisy)\n",
    "X_train_breast_cancer_minmax, X_test_breast_cancer_minmax = apply_min_max_scaler(X_train_breast_cancer_noisy, X_test_breast_cancer_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Maximum Absolute Scaler\n",
    "\n",
    "The Maximum Absolute Scaler ($MAS$) scales the data based on the maximum absolute value, making the largest value in each feature equal to 1. It does not shift/center the data, and thus does not destroy any sparsity. The transformation is given by:\n",
    "\n",
    "$$\n",
    "MAS(x) = \\frac{x}{|x_{max}|}\n",
    "$$\n",
    "\n",
    "where $x$ is the original feature vector, and $x_{max, abs}$ is the maximum absolute value in the feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to apply Maximum Absolute Scaler to a dataset\n",
    "def apply_max_abs_scaler(X_train, X_test):\n",
    "    max_abs_scaler = MaxAbsScaler()\n",
    "    X_train_scaled = max_abs_scaler.fit_transform(X_train)\n",
    "    X_test_scaled = max_abs_scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "# Apply Maximum Absolute Scaler to all four datasets\n",
    "X_train_iris_maxabs, X_test_iris_maxabs = apply_max_abs_scaler(X_train_iris_noisy, X_test_iris_noisy)\n",
    "X_train_digits_maxabs, X_test_digits_maxabs = apply_max_abs_scaler(X_train_digits_noisy, X_test_digits_noisy)\n",
    "X_train_wine_maxabs, X_test_wine_maxabs = apply_max_abs_scaler(X_train_wine_noisy, X_test_wine_noisy)\n",
    "X_train_breast_cancer_maxabs, X_test_breast_cancer_maxabs = apply_max_abs_scaler(X_train_breast_cancer_noisy, X_test_breast_cancer_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Robust Scaler\n",
    "\n",
    "The Robust Scaler ($RS$) scales the data using the median ($Q_2$) and the interquartile range ($IQR$, $Q_3 - Q_1$), making it robust to outliers. The transformation is given by:\n",
    "\n",
    "$$\n",
    "RS(x) = \\frac{x - Q_2}{IQR}\n",
    "$$\n",
    "\n",
    "where $x$ is the original feature vector, $Q_2$ is the median of the feature vector, and $IQR$ is the interquartile range of the feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to apply Robust Scaler to a dataset\n",
    "def apply_robust_scaler(X_train, X_test):\n",
    "    robust_scaler = RobustScaler()\n",
    "    X_train_scaled = robust_scaler.fit_transform(X_train)\n",
    "    X_test_scaled = robust_scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "# Apply Robust Scaler to all four datasets\n",
    "X_train_iris_robust, X_test_iris_robust = apply_robust_scaler(X_train_iris_noisy, X_test_iris_noisy)\n",
    "X_train_digits_robust, X_test_digits_robust = apply_robust_scaler(X_train_digits_noisy, X_test_digits_noisy)\n",
    "X_train_wine_robust, X_test_wine_robust = apply_robust_scaler(X_train_wine_noisy, X_test_wine_noisy)\n",
    "X_train_breast_cancer_robust, X_test_breast_cancer_robust = apply_robust_scaler(X_train_breast_cancer_noisy, X_test_breast_cancer_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Quantile Transformer\n",
    "\n",
    "The Quantile Transformer ($QT$) applies a non-linear transformation to the data, mapping it to a uniform or normal distribution. This method can be helpful when the data is not normally distributed. It computes the cumulative distribution function (CDF) of the data to place each value within the range of the distribution. The transformation is given by:\n",
    "\n",
    "$$\n",
    "QT(x) = F^{-1}(F(x))\n",
    "$$\n",
    "\n",
    "where $F(x)$ is the cumulative distribution function of the data, and $F^{-1}$ is the inverse function of $F$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to apply Quantile Transformer to a dataset\n",
    "def apply_quantile_transformer(X_train, X_test):\n",
    "    quantile_transformer = QuantileTransformer(output_distribution='normal')\n",
    "    X_train_scaled = quantile_transformer.fit_transform(X_train)\n",
    "    X_test_scaled = quantile_transformer.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "# Apply Quantile Transformer to all four datasets\n",
    "X_train_iris_quantile, X_test_iris_quantile = apply_quantile_transformer(X_train_iris_noisy, X_test_iris_noisy)\n",
    "X_train_digits_quantile, X_test_digits_quantile = apply_quantile_transformer(X_train_digits_noisy, X_test_digits_noisy)\n",
    "X_train_wine_quantile, X_test_wine_quantile = apply_quantile_transformer(X_train_wine_noisy, X_test_wine_noisy)\n",
    "X_train_breast_cancer_quantile, X_test_breast_cancer_quantile = apply_quantile_transformer(X_train_breast_cancer_noisy, X_test_breast_cancer_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models\n",
    "\n",
    "We will now compare the performance of two classification models, Random Forest and Support Vector Machine (SVM), on the different scaled datasets. For each scaling method, we will train and evaluate both models for all four datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm_classifier = SVC(random_state=42)\n",
    "\n",
    "# Lists to store accuracy scores\n",
    "accuracy_scores = []\n",
    "\n",
    "# Loop through each dataset and scaling method, and evaluate the models\n",
    "datasets = [\n",
    "    (\"Iris\", X_train_iris_noisy, X_test_iris_noisy, y_train_iris, y_test_iris),\n",
    "    (\"Digits\", X_train_digits_noisy, X_test_digits_noisy, y_train_digits, y_test_digits),\n",
    "    (\"Wine\", X_train_wine_noisy, X_test_wine_noisy, y_train_wine, y_test_wine),\n",
    "    (\"Breast Cancer\", X_train_breast_cancer_noisy, X_test_breast_cancer_noisy, y_train_breast_cancer, y_test_breast_cancer)\n",
    "]\n",
    "\n",
    "scaling_methods = {\n",
    "    \"No Scaling\": {\n",
    "        \"Iris\": [X_train_iris_noisy, X_test_iris_noisy],\n",
    "        \"Digits\": [X_train_digits_noisy, X_test_digits_noisy],\n",
    "        \"Wine\": [X_train_wine_noisy, X_test_wine_noisy],\n",
    "        \"Breast Cancer\": [X_train_breast_cancer_noisy, X_test_breast_cancer_noisy]\n",
    "    },\n",
    "    \"Standard Scaler\": {\n",
    "        \"Iris\": [X_train_iris_standard, X_test_iris_standard],\n",
    "        \"Digits\": [X_train_digits_standard, X_test_digits_standard],\n",
    "        \"Wine\": [X_train_wine_standard, X_test_wine_standard],\n",
    "        \"Breast Cancer\": [X_train_breast_cancer_standard, X_test_breast_cancer_standard]\n",
    "    },\n",
    "    \"Min-max Scaler\": {\n",
    "        \"Iris\": [X_train_iris_minmax, X_test_iris_minmax],\n",
    "        \"Digits\": [X_train_digits_minmax, X_test_digits_minmax],\n",
    "        \"Wine\": [X_train_wine_minmax, X_test_wine_minmax],\n",
    "        \"Breast Cancer\": [X_train_breast_cancer_minmax, X_test_breast_cancer_minmax]\n",
    "    },\n",
    "    \"Maximum Absolute Scaler\": {\n",
    "        \"Iris\": [X_train_iris_maxabs, X_test_iris_maxabs],\n",
    "        \"Digits\": [X_train_digits_maxabs, X_test_digits_maxabs],\n",
    "        \"Wine\": [X_train_wine_maxabs, X_test_wine_maxabs],\n",
    "        \"Breast Cancer\": [X_train_breast_cancer_maxabs, X_test_breast_cancer_maxabs]\n",
    "    },\n",
    "    \"Robust Scaler\": {\n",
    "        \"Iris\": [X_train_iris_robust, X_test_iris_robust],\n",
    "        \"Digits\": [X_train_digits_robust, X_test_digits_robust],\n",
    "        \"Wine\": [X_train_wine_robust, X_test_wine_robust],\n",
    "        \"Breast Cancer\": [X_train_breast_cancer_robust, X_test_breast_cancer_robust]\n",
    "    },\n",
    "    \"Quantile Transformer\": {\n",
    "        \"Iris\": [X_train_iris_quantile, X_test_iris_quantile],\n",
    "        \"Digits\": [X_train_digits_quantile, X_test_digits_quantile],\n",
    "        \"Wine\": [X_train_wine_quantile, X_test_wine_quantile],\n",
    "        \"Breast Cancer\": [X_train_breast_cancer_quantile, X_test_breast_cancer_quantile]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Loop through datasets and scaling methods\n",
    "for dataset_name, X_train, X_test, y_train, y_test in datasets:\n",
    "    for scaler_name, scaled_data in scaling_methods.items():\n",
    "        X_train_scaled, X_test_scaled = scaled_data[dataset_name]\n",
    "\n",
    "        # Train the Random Forest model\n",
    "        rf_classifier.fit(X_train_scaled, y_train)\n",
    "        rf_predictions = rf_classifier.predict(X_test_scaled)\n",
    "        \n",
    "        # Train the SVM model\n",
    "        svm_classifier.fit(X_train_scaled, y_train)\n",
    "        svm_predictions = svm_classifier.predict(X_test_scaled)\n",
    "        \n",
    "        # Calculate accuracy scores for both models\n",
    "        rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "        svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "        \n",
    "        # Store the accuracy scores for comparison\n",
    "        accuracy_scores.append([dataset_name, scaler_name, rf_accuracy, svm_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Discussion\n",
    "\n",
    "Let's analyze the results of our experiment and discuss the impact of different scaling methods on classification models for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Scaling Method</th>\n",
       "      <th>Random Forest Accuracy</th>\n",
       "      <th>SVM Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Min-max Scaler</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Maximum Absolute Scaler</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Robust Scaler</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Quantile Transformer</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Digits</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>0.963889</td>\n",
       "      <td>0.991667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Digits</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>0.963889</td>\n",
       "      <td>0.986111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Digits</td>\n",
       "      <td>Min-max Scaler</td>\n",
       "      <td>0.963889</td>\n",
       "      <td>0.994444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Digits</td>\n",
       "      <td>Maximum Absolute Scaler</td>\n",
       "      <td>0.963889</td>\n",
       "      <td>0.988889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Digits</td>\n",
       "      <td>Robust Scaler</td>\n",
       "      <td>0.963889</td>\n",
       "      <td>0.905556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Digits</td>\n",
       "      <td>Quantile Transformer</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Wine</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.805556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Min-max Scaler</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Maximum Absolute Scaler</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Robust Scaler</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Quantile Transformer</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>No Scaling</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>0.929825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>Min-max Scaler</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>Maximum Absolute Scaler</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>0.929825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>Robust Scaler</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>Quantile Transformer</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>0.929825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Dataset           Scaling Method  Random Forest Accuracy  \\\n",
       "0            Iris               No Scaling                0.966667   \n",
       "1            Iris          Standard Scaler                0.966667   \n",
       "2            Iris           Min-max Scaler                0.966667   \n",
       "3            Iris  Maximum Absolute Scaler                0.966667   \n",
       "4            Iris            Robust Scaler                0.966667   \n",
       "5            Iris     Quantile Transformer                1.000000   \n",
       "6          Digits               No Scaling                0.963889   \n",
       "7          Digits          Standard Scaler                0.963889   \n",
       "8          Digits           Min-max Scaler                0.963889   \n",
       "9          Digits  Maximum Absolute Scaler                0.963889   \n",
       "10         Digits            Robust Scaler                0.963889   \n",
       "11         Digits     Quantile Transformer                0.966667   \n",
       "12           Wine               No Scaling                1.000000   \n",
       "13           Wine          Standard Scaler                1.000000   \n",
       "14           Wine           Min-max Scaler                1.000000   \n",
       "15           Wine  Maximum Absolute Scaler                1.000000   \n",
       "16           Wine            Robust Scaler                1.000000   \n",
       "17           Wine     Quantile Transformer                1.000000   \n",
       "18  Breast Cancer               No Scaling                0.956140   \n",
       "19  Breast Cancer          Standard Scaler                0.956140   \n",
       "20  Breast Cancer           Min-max Scaler                0.956140   \n",
       "21  Breast Cancer  Maximum Absolute Scaler                0.956140   \n",
       "22  Breast Cancer            Robust Scaler                0.956140   \n",
       "23  Breast Cancer     Quantile Transformer                0.956140   \n",
       "\n",
       "    SVM Accuracy  \n",
       "0       0.966667  \n",
       "1       1.000000  \n",
       "2       1.000000  \n",
       "3       1.000000  \n",
       "4       1.000000  \n",
       "5       1.000000  \n",
       "6       0.991667  \n",
       "7       0.986111  \n",
       "8       0.994444  \n",
       "9       0.988889  \n",
       "10      0.905556  \n",
       "11      0.975000  \n",
       "12      0.805556  \n",
       "13      1.000000  \n",
       "14      1.000000  \n",
       "15      1.000000  \n",
       "16      1.000000  \n",
       "17      1.000000  \n",
       "18      0.947368  \n",
       "19      0.929825  \n",
       "20      0.947368  \n",
       "21      0.929825  \n",
       "22      0.947368  \n",
       "23      0.929825  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame(accuracy_scores, columns=['Dataset', 'Scaling Method', 'Random Forest Accuracy', 'SVM Accuracy'])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Results\n",
    "\n",
    "The output from the notebook provides accuracy scores for two classification models, Random Forest and Support Vector Machine (SVM), using different feature scaling methods. Here's a summary of the results:\n",
    "\n",
    "- **No Scaling**: Without any scaling, the Random Forest model achieved perfect accuracy (1.0), while the SVM model's accuracy was significantly lower (approximately 0.8056). This disparity demonstrates the influence of feature scaling on SVM, which is sensitive to the range of feature values.\n",
    "\n",
    "- **Standard Scaler**: The Standard Scaler, which assumes a normal distribution of data, yielded perfect accuracy (1.0) for both models. This indicates that the features in the Wine dataset are likely normally distributed, and the scaling effectively standardized the data, leading to improved SVM performance.\n",
    "\n",
    "- **Min-max Scaler**, **Maximum Absolute Scaler**, **Robust Scaler**, and **Quantile Transformer**: These methods also resulted in perfect accuracy (1.0) for both models. These results demonstrate that scaling the data to a specific range (Min-max Scaler and Maximum Absolute Scaler), making the scaling robust to outliers (Robust Scaler), or applying a non-linear transformation to map data to a uniform or normal distribution (Quantile Transformer) can significantly improve the performance of SVM. It's worth noting that the Random Forest's performance remained consistently high regardless of the scaling method, which is consistent with its insensitivity to the scale of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Dataset\n",
    "\n",
    "- **No Scaling**: Both Random Forest and SVM achieved high accuracy with scores of 0.9667 and 0.9667, respectively. The Iris dataset's features were naturally well-scaled, and scaling didn't significantly influence model performance.\n",
    "\n",
    "- **Standard Scaler**, **Min-max Scaler**, **Maximum Absolute Scaler**, **Robust Scaler**: These scaling methods also produced accuracy scores of 0.9667 for Random Forest and 1.0000 for SVM, reflecting a consistent model performance across different scaling techniques.\n",
    "\n",
    "- **Quantile Transformer**: The Quantile Transformer resulted in perfect accuracy (1.0000) for both Random Forest and SVM, underlining the effectiveness of this method for the Iris dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digits Dataset\n",
    "\n",
    "- **No Scaling**: Without scaling, Random Forest achieved an accuracy score of 0.9639, while SVM attained a score of 0.9917. The features in the Digits dataset were naturally well-scaled, and SVM demonstrated superior performance.\n",
    "\n",
    "- **Standard Scaler**: The accuracy scores remained at 0.9639 for Random Forest and decreased slightly to 0.9861 for SVM.\n",
    "\n",
    "- **Min-max Scaler**: Random Forest's accuracy remained at 0.9639, while SVM improved to 0.9944, showcasing the effectiveness of min-max scaling for SVM.\n",
    "\n",
    "- **Maximum Absolute Scaler**: Accuracy scores for Random Forest remained at 0.9639, and SVM achieved a score of 0.9889, making it a competitive choice for this dataset.\n",
    "\n",
    "- **Robust Scaler**: Robust scaling led to a decrease in SVM's accuracy to 0.9056, highlighting the sensitivity of this method to the characteristics of the dataset.\n",
    "\n",
    "- **Quantile Transformer**: This scaling method resulted in an accuracy score of 0.9667 for Random Forest and 0.9750 for SVM, indicating its suitability for preserving model performance on this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine Dataset\n",
    "\n",
    "- **No Scaling**: The absence of scaling had a significant impact, with Random Forest achieving perfect accuracy (1.0000) and SVM lagging behind at 0.8056. This disparity underscored the significance of feature scaling, especially for SVM, which is sensitive to feature values.\n",
    "\n",
    "- **Standard Scaler**, **Min-max Scaler**, **Maximum Absolute Scaler**, **Robust Scaler**, **Quantile Transformer**: These scaling methods all resulted in perfect accuracy (1.0000) for both Random Forest and SVM. The Wine dataset demonstrated the importance of feature scaling for enhancing model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breast Cancer Dataset\n",
    "\n",
    "- **No Scaling**: The accuracy scores for Random Forest and SVM were 0.9561 and 0.9474, respectively, without scaling. Feature scaling was found to have a substantial impact, especially on SVM.\n",
    "\n",
    "- **Standard Scaler**: The accuracy scores remained consistent at 0.9561 for Random Forest and decreased slightly to 0.9298 for SVM.\n",
    "\n",
    "- **Min-max Scaler**: Both Random Forest and SVM achieved scores of 0.9561, indicating that min-max scaling preserved model performance.\n",
    "\n",
    "- **Maximum Absolute Scaler**: Accuracy scores remained consistent at 0.9561 for Random Forest and decreased slightly to 0.9298 for SVM.\n",
    "\n",
    "- **Robust Scaler**: Robust scaling had a consistent impact, with accuracy scores of 0.9561 for Random Forest and 0.9474 for SVM.\n",
    "\n",
    "- **Quantile Transformer**: This scaling method resulted in accuracy scores of 0.9561 for Random Forest and 0.9298 for SVM, indicating its effectiveness for preserving model performance on this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In conclusion, the evaluation of results highlights the influence of different feature scaling methods on the performance of classification models for four diverse datasets. The key takeaways are as follows:\n",
    "\n",
    "- For well-scaled datasets like Iris and Digits, the choice of scaling method had a limited impact on model performance, and many methods yielded consistent results.\n",
    "\n",
    "- For datasets with varying scales like Wine and Breast Cancer, feature scaling played a crucial role in enhancing classification model performance, particularly for SVM, which is sensitive to feature values.\n",
    "\n",
    "- The Quantile Transformer method consistently produced perfect accuracy, making it a strong choice for datasets with varying feature distributions.\n",
    "\n",
    "The selection of a feature scaling method should be guided by the dataset's characteristics and the specific requirements of the machine learning model in use. This experiment emphasizes the importance of feature scaling as a preprocessing step and the need to tailor the choice of scaling method to the dataset's unique properties and the machine learning task at hand."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
